{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl import ValueAction\n",
    "\n",
    "value_action = ValueAction(100, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "maze_map = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
    "            [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 0, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]\n",
    "maze_map = np.array(maze_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 9], dtype=int64),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(maze_map[:, x] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from train import train_dql, ValueAction, Environment, EPolicy\n",
    "from environment import WALL_M, Point, Agent\n",
    "from agents import AgentVision\n",
    "import numpy as np\n",
    "\n",
    "# Maze Parameters\n",
    "STATE_SIZE = 500 # observation size * types of tiles\n",
    "#hyper parameters\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "DIM = 0.9\n",
    "ALPHA = 0.001\n",
    "NUM_EPISODES = 8000\n",
    "MAX_STEPS = 100\n",
    "TAU = 0.1\n",
    "# First 250\n",
    "# EPSILON = 0.6\n",
    "# EPSILON_DECAY = 0.9999\n",
    "# After 250\n",
    "EPSILON = 0.1\n",
    "EPSILON_DECAY = 0.99999\n",
    "DROPOUT = 0.1\n",
    "STEPS_PER_UPDATE = 100\n",
    "ARCHITECTURE = 'one_hidden'\n",
    "N = 1\n",
    "value_action = ValueAction(state_size=STATE_SIZE, architecture=ARCHITECTURE, batch_size=BATCH_SIZE, buffer_size=BUFFER_SIZE, steps_per_update=STEPS_PER_UPDATE, dim=DIM, alpha=ALPHA, tau=TAU, n=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mokrota\\Documents\\GitHub\\RL_projects\\dql\\rl.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(path)\n"
     ]
    }
   ],
   "source": [
    "value_action.load('../one_check.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: network.0.weight | Weights: tensor([[ 0.0290,  0.0444,  0.0091,  ...,  0.0018, -0.0292, -0.0370],\n",
      "        [ 0.0216, -1.1514, -0.0066,  ...,  0.0247, -0.0801,  0.0206],\n",
      "        [-0.0255, -0.0308,  0.0298,  ..., -0.0382, -0.0626, -0.0132],\n",
      "        ...,\n",
      "        [-0.0161, -0.6540,  0.0114,  ..., -0.0103, -0.1775, -0.0074],\n",
      "        [ 0.0259,  0.0311,  0.0046,  ..., -0.0115, -0.0127, -0.0112],\n",
      "        [-0.0123,  0.4271, -0.0012,  ...,  0.0305,  0.4410, -0.0146]],\n",
      "       device='cuda:0')\n",
      "Layer: network.0.bias | Weights: tensor([-7.8636e-02, -1.5917e-01, -1.5613e-02, -2.2471e-01, -9.7867e-02,\n",
      "        -6.3118e-02,  1.9823e-03, -3.5478e-02, -6.3982e-02,  2.7876e-02,\n",
      "        -5.7496e-02, -8.4765e-02, -9.0141e-02, -9.5881e-02, -1.0661e-01,\n",
      "        -3.3833e-01, -2.6717e-01,  6.3523e-03,  6.2787e-03,  2.8073e-02,\n",
      "        -4.0217e-02, -3.4348e-01, -4.6361e-02, -5.9466e-02, -1.9589e-01,\n",
      "        -2.4263e-02, -2.3970e-01, -1.4956e-02, -1.5098e-01, -5.1749e-01,\n",
      "        -3.2552e-02,  7.2185e-03, -6.1802e-03, -1.3310e-01,  1.4440e-02,\n",
      "        -5.1659e-01, -3.2997e-01, -2.1616e-01, -4.8122e-02, -8.4448e-02,\n",
      "        -3.5044e-01, -4.7199e-01, -5.2311e-01, -3.8048e-02, -2.3022e-02,\n",
      "         5.6904e-04, -6.5016e-02, -1.2952e-01, -2.8320e-01, -3.1316e-01,\n",
      "        -5.5827e-01,  2.0422e-02, -6.5140e-02, -9.1631e-02,  2.1643e-02,\n",
      "        -5.3229e-02, -5.2374e-01, -1.2505e-01, -3.2315e-01,  1.6771e-02,\n",
      "         1.9693e-02, -8.0679e-04, -6.1865e-01,  1.5319e-02, -1.6086e-01,\n",
      "        -7.5787e-02,  1.6685e-02, -3.0050e-02, -5.6989e-02, -3.5612e-01,\n",
      "        -6.6460e-01,  1.5040e-01, -5.6629e-01, -4.9148e-02,  4.4458e-02,\n",
      "        -1.2099e-02, -5.3103e-01,  2.3036e-02, -7.2084e-02, -7.1642e-02,\n",
      "        -6.9112e-02, -6.6005e-01, -1.4523e-02, -3.3361e-01,  3.1271e-02,\n",
      "        -2.6039e-01, -4.8515e-01, -1.7024e-01, -1.1460e-02,  1.6912e-02,\n",
      "        -1.8071e-01, -3.6165e-02, -6.2875e-02, -5.2896e-03, -2.0086e-01,\n",
      "        -2.7581e-01, -5.4459e-02, -2.9191e-03, -6.0978e-03, -1.5105e-01,\n",
      "         3.7481e-02, -1.7645e-02, -1.2387e-01, -3.6542e-01, -6.6324e-01,\n",
      "        -1.2680e-01, -6.8865e-01, -1.0085e-01, -5.7994e-02, -1.3002e-01,\n",
      "        -3.4140e-01, -1.6824e-01,  7.0573e-03, -1.5348e-01, -3.2875e-02,\n",
      "        -1.6625e-02, -1.6360e-02, -7.3387e-02,  8.9040e-04,  2.3632e-01,\n",
      "        -1.1389e-01, -4.9714e-02, -1.5652e-02, -2.6275e-01, -5.5665e-02,\n",
      "        -4.4075e-01, -1.7755e-02, -1.6905e-01], device='cuda:0')\n",
      "Layer: network.3.weight | Weights: tensor([[-0.0383, -0.5472, -0.0509,  ..., -0.6788,  0.0249, -3.5626],\n",
      "        [-0.1236, -1.1418,  0.0144,  ..., -1.4432,  0.0091, -2.5367],\n",
      "        [ 0.0066, -0.4568, -0.0285,  ..., -1.0988, -0.0327, -1.8958],\n",
      "        ...,\n",
      "        [-0.0444, -1.0941, -0.0815,  ..., -1.5846, -0.0057, -1.0102],\n",
      "        [ 0.0484,  0.5767,  0.0418,  ..., -1.4351,  0.0399, -0.3891],\n",
      "        [-0.0253, -0.3923, -0.0505,  ..., -0.8295,  0.0697, -0.4801]],\n",
      "       device='cuda:0')\n",
      "Layer: network.3.bias | Weights: tensor([-4.9580e+00, -4.6792e+00, -1.0194e+00, -3.6026e+00,  4.8799e-01,\n",
      "        -3.6402e+00, -1.0848e+00, -3.3950e-02, -3.5190e+00,  1.7189e-01,\n",
      "        -1.7221e+00,  1.9110e-01, -3.9410e+00, -3.2942e+00, -1.8137e-01,\n",
      "        -2.9494e-01, -2.9962e-03, -1.4028e+00, -5.3254e+00, -3.6586e+00,\n",
      "        -4.9136e+00, -7.3749e-01,  2.9941e-01, -1.8963e+00, -2.5685e+00,\n",
      "        -2.3731e+00, -1.1596e+00, -2.9444e+00, -5.5309e+00, -4.6583e+00,\n",
      "        -1.4474e+00, -3.5117e+00, -2.1119e+00, -3.8870e+00, -6.8767e-01,\n",
      "        -5.1029e+00, -1.4400e+00,  1.5223e-01, -3.6082e+00,  5.3157e-01,\n",
      "        -5.6200e-01, -3.0661e+00, -2.4452e+00, -1.5709e+00, -4.2228e+00,\n",
      "        -1.2903e+00, -2.2490e+00, -3.6751e+00, -4.6181e-02, -5.9088e-03,\n",
      "        -1.6283e+00, -4.8871e-02, -3.2099e+00, -4.5378e-01, -2.0001e+00,\n",
      "        -4.4152e+00, -5.6006e-02, -1.2133e+00, -2.8539e+00, -3.9999e+00,\n",
      "        -7.3205e-01, -4.4139e+00,  4.1802e-01, -2.0891e+00, -1.4632e+00,\n",
      "        -3.1040e+00, -2.1361e-01, -4.0081e+00, -1.0871e+00, -3.2805e+00,\n",
      "        -2.8734e+00, -2.8632e+00, -3.4065e+00, -3.3890e-01, -2.0609e+00,\n",
      "        -1.1653e+00, -2.4079e+00, -2.3459e+00, -2.8560e+00, -1.6412e+00,\n",
      "        -2.1441e+00, -6.5328e+00, -4.1912e-03, -3.3097e+00, -3.3831e+00,\n",
      "        -2.0825e+00, -5.6614e+00, -1.8221e-02, -4.7722e+00, -3.6570e+00,\n",
      "        -5.0496e+00, -2.9062e+00, -2.1920e+00, -1.0684e+00, -1.8482e-02,\n",
      "        -2.8568e+00,  7.5217e-02, -1.1991e+00, -4.3278e+00, -3.0890e-02,\n",
      "        -1.7519e+00, -4.5728e+00, -4.8269e+00, -2.9679e+00, -4.4419e+00,\n",
      "        -4.1399e+00, -6.8739e-01, -5.1042e+00,  1.1781e-01, -4.1049e+00,\n",
      "        -2.1597e+00, -4.6744e+00, -3.7378e-01, -2.2689e+00, -3.4082e+00,\n",
      "        -3.2121e+00, -2.0096e+00, -2.4327e+00, -3.2352e+00,  3.2937e-01,\n",
      "        -1.9227e+00, -4.7769e+00, -8.2724e-03, -2.4307e+00, -4.2788e-01,\n",
      "        -2.6660e+00, -3.1086e+00, -1.7975e+00], device='cuda:0')\n",
      "Layer: network.6.weight | Weights: tensor([[-4.0968e-01,  1.3790e+00,  1.0994e+00, -1.6927e+00, -2.9358e-01,\n",
      "         -6.3324e-01, -1.0561e+00,  5.1906e-01,  2.9776e+00,  3.5121e-01,\n",
      "         -2.2325e-01, -5.4811e-01,  3.7050e-01, -2.7655e+00,  1.9532e+00,\n",
      "          1.0149e+00, -6.1939e-01, -6.6555e-01,  2.8499e-01, -3.4395e-02,\n",
      "         -1.3898e-01, -8.7566e-03,  2.2265e+00, -3.4726e-01, -1.2176e-01,\n",
      "          6.6306e-01,  1.7480e-01,  1.7317e-01,  1.7558e+00, -1.4620e-01,\n",
      "          4.2194e-01, -4.0220e-03,  3.0566e-01, -3.8349e-01,  1.3444e+00,\n",
      "          9.7220e-01,  1.1720e-01, -3.0157e-01, -7.1529e-01, -1.3286e+00,\n",
      "          3.7718e-01, -4.1132e-01, -4.2879e-02,  8.3484e-01,  4.5250e+00,\n",
      "          7.4184e-01, -1.1869e+00, -1.0243e+00,  9.1723e-01,  1.3511e+00,\n",
      "         -4.1377e-01,  3.5215e-01,  2.0698e+00,  8.5085e-01, -1.8557e+00,\n",
      "         -6.4736e-01,  1.7973e+00, -1.2213e+00,  1.8393e+00,  2.1813e-01,\n",
      "          3.3248e-01,  2.8699e+00, -2.3479e-01,  6.6689e-01,  1.5026e+00,\n",
      "         -9.7358e-01, -7.5149e-01,  6.3591e-02,  6.9333e-01,  1.5997e-01,\n",
      "          1.1401e+00, -2.7124e-01,  7.6291e-01, -6.0484e-01,  1.0590e+00,\n",
      "         -5.6392e-01, -7.1002e-02,  4.5884e-01,  2.0695e+00,  2.1318e+00,\n",
      "          5.9638e-01, -1.0742e-01,  1.4442e+00, -8.8741e-01, -6.1520e-02,\n",
      "         -9.4711e-01, -4.3404e-01, -2.0348e-01, -5.4084e-01,  2.7932e-01,\n",
      "          1.4835e+00, -7.1181e-01,  1.8461e+00,  8.6738e-01,  4.5482e-01,\n",
      "         -1.2074e-01, -5.4616e-01, -7.1464e-01,  3.1788e+00,  9.1352e-01,\n",
      "         -2.0024e-01, -9.3955e-01, -7.2726e-01, -2.9614e-01,  1.3881e+00,\n",
      "          7.4229e-01,  1.0020e+00,  2.4559e+00,  7.5557e-01,  1.2933e+00,\n",
      "          6.6976e-02,  5.6611e-01,  6.0757e-01,  1.5980e+00, -1.9733e-01,\n",
      "         -5.6660e-01,  1.8005e+00, -1.0212e+00, -4.3360e-02, -3.4463e-01,\n",
      "          4.9460e-01, -3.6251e-01, -7.7539e-01, -2.2878e-01,  1.8781e+00,\n",
      "          1.9763e-01,  1.5790e-01, -4.9184e-01],\n",
      "        [ 3.2117e-01,  7.2837e-02,  1.1083e+00,  2.8203e+00, -1.4891e+00,\n",
      "          1.6350e-01, -1.0701e+00, -7.6930e-01,  1.2755e+00,  5.1918e-01,\n",
      "         -4.1430e-01,  6.4193e-01,  3.9678e-01,  5.2934e+00,  1.8718e+00,\n",
      "          9.4659e-02,  2.0582e-03, -2.0377e+00,  5.3005e+00,  1.1898e+00,\n",
      "          4.7133e-01,  1.0654e+00, -1.3938e-01,  3.9435e+00,  1.0675e+00,\n",
      "          1.4888e+00, -5.3874e-01, -1.2628e+00,  2.9556e+00, -8.4751e-01,\n",
      "         -3.5317e-03,  8.7697e-01,  8.6572e-01,  4.6021e+00,  3.8202e-02,\n",
      "         -6.4738e-01,  6.5527e-01,  1.3040e+00, -1.5920e+00, -1.8596e+00,\n",
      "          1.3024e+00, -4.1679e-01,  2.1954e-01,  6.4896e-01, -9.7144e-01,\n",
      "         -7.7032e-01, -3.1226e+00,  2.1079e-02, -5.3166e-01,  4.3427e-01,\n",
      "          4.4460e-01,  8.7826e-01, -8.5594e-01, -4.1370e-01,  1.1406e+00,\n",
      "         -5.8124e-01,  1.8332e+00, -7.3736e-01,  2.3972e+00,  4.9309e-02,\n",
      "          5.1543e-02, -2.1245e-01, -7.9505e-01, -2.8831e-01,  1.0266e+00,\n",
      "         -1.5717e+00,  1.4704e+00,  3.9441e-02,  3.7069e-01, -9.2099e-01,\n",
      "          5.3955e-01,  1.5801e+00, -5.4152e-01, -1.0846e-01, -6.9071e-01,\n",
      "          6.5595e-02, -1.2976e-01, -9.1317e-01,  4.5687e-01,  1.0348e+00,\n",
      "          1.1546e+00,  2.4002e+00,  1.5395e+00,  3.9337e+00, -2.0838e-01,\n",
      "         -1.2875e+00,  1.2471e-01,  1.0647e+00,  6.2692e-01,  4.2835e+00,\n",
      "          8.8552e-01,  2.6003e-03,  2.6942e+00,  3.0603e-01,  3.1390e-01,\n",
      "          3.4240e-01,  1.2347e+00, -1.1732e+00,  9.5369e-01, -1.6205e-01,\n",
      "          1.9999e+00, -1.0545e+00, -9.4439e-01,  7.8846e-01, -7.8487e-01,\n",
      "          2.6926e-01,  7.2636e-01, -2.0756e-01,  1.1386e+00,  1.9161e+00,\n",
      "          1.4384e+00,  1.1647e+00,  7.9667e-01,  1.6725e+00,  1.3064e+00,\n",
      "         -2.7827e-01, -5.8599e-01, -1.3792e+00, -8.9182e-01,  1.1727e-01,\n",
      "         -1.6717e-01,  2.0263e+00, -2.1395e-01,  9.0921e-01,  1.8098e-01,\n",
      "         -3.6399e-01,  2.5075e-02,  2.8438e+00],\n",
      "        [ 1.0543e-02,  1.2377e+00, -1.8623e-02,  5.1807e-01,  1.7399e+00,\n",
      "         -3.5509e-01,  2.5804e+00, -2.0339e-01, -7.3833e-02, -5.1532e-01,\n",
      "          5.6903e-02,  3.4890e-01,  4.9935e-01, -2.1989e-01, -1.1034e+00,\n",
      "         -1.8490e+00, -1.1285e+00,  1.3308e+00,  6.3441e-01,  1.1352e+00,\n",
      "          6.9776e-01, -1.5017e+00, -1.3265e+00, -3.0505e-02, -4.5141e-02,\n",
      "          1.2351e-01, -4.4562e-01, -6.9034e-02, -6.3141e-01,  6.8872e-01,\n",
      "          9.9719e-01,  5.6098e-01,  5.4312e-01,  1.1444e-02, -5.6644e-01,\n",
      "         -2.8296e-01, -1.4593e+00, -1.3346e+00,  9.8213e-01,  1.6008e+00,\n",
      "          2.9236e-01, -3.1487e-01,  2.3933e-01,  6.8494e-01,  8.2529e-01,\n",
      "          2.9954e-01,  7.0067e-01, -1.6030e+00, -8.2946e-01, -5.4754e-01,\n",
      "          5.8234e-01, -6.5581e-01,  6.8322e-01,  8.5761e-01, -1.2449e+00,\n",
      "         -5.6090e-01, -7.7725e-01,  8.2114e-01, -6.0911e-01,  1.7253e+00,\n",
      "          9.2380e-01,  3.2966e-02, -5.3344e-01,  1.7269e+00, -2.5993e-01,\n",
      "          9.4662e-01, -4.4447e-01,  3.9641e+00,  8.5911e-01,  9.6910e-01,\n",
      "         -3.2204e-01,  7.6326e-01,  6.3408e-01,  2.2943e-01, -1.1136e+00,\n",
      "         -8.7840e-01,  5.1063e-01,  3.2631e-01,  7.4591e-01, -1.1922e+00,\n",
      "         -1.8943e-01,  1.3680e+00, -8.3823e-01, -3.1016e-01,  8.3266e-01,\n",
      "          2.6739e+00, -8.6454e-01, -1.2390e+00, -1.0312e+00, -3.7074e-01,\n",
      "          2.1627e+00, -3.9119e-01,  2.4258e-01, -3.3281e-01, -2.1031e-01,\n",
      "          3.8850e-01, -1.1485e+00,  1.8959e+00,  2.7932e-01, -2.8182e+00,\n",
      "         -1.9244e-01,  1.0982e+00,  8.6436e-01, -1.2336e-01,  3.4769e+00,\n",
      "          3.6280e+00, -1.3187e-01,  1.6045e-01, -2.5497e-01, -1.5538e-01,\n",
      "         -6.5601e-01,  2.6028e+00, -7.3299e-01, -3.8540e-01,  2.9299e+00,\n",
      "          3.5838e-01,  9.0939e-01,  1.3658e+00,  1.1973e+00, -8.3677e-01,\n",
      "          2.0793e+00,  8.2502e-01, -1.0524e-01,  7.5796e-01,  9.7178e-02,\n",
      "          4.5666e-01,  1.3806e+00,  3.5629e-01],\n",
      "        [ 1.8830e+00, -4.0070e-01, -5.9293e-02,  2.1423e+00,  1.6579e+00,\n",
      "          1.7634e+00,  2.4617e+00,  4.0842e-01, -4.9416e-01, -2.9803e-01,\n",
      "         -1.3305e-01, -1.0157e+00, -2.5978e-01, -9.9370e-02,  3.6377e-01,\n",
      "         -6.0384e-01, -1.7085e+00,  2.0455e+00,  1.0960e-01, -1.1618e+00,\n",
      "          1.7090e+00,  7.5294e-02, -4.5808e-01,  4.1295e-01, -5.5781e-01,\n",
      "         -7.5964e-01,  1.5056e+00,  1.6650e+00, -1.2086e+00,  9.9277e-01,\n",
      "          7.6479e-01,  1.9037e+00, -2.4975e-01, -3.4820e-01, -9.7541e-01,\n",
      "          2.1750e+00,  7.0803e-02, -4.7967e-01,  1.4682e+00,  1.5791e+00,\n",
      "          8.6066e-01,  2.7721e+00, -8.1241e-01, -1.5437e+00, -1.0601e+00,\n",
      "         -9.1178e-01,  2.9879e-01,  2.0818e+00, -1.0119e+00, -3.3714e-01,\n",
      "         -1.8875e-01, -5.2601e-01,  6.3506e-01,  5.0733e-01,  3.8552e-01,\n",
      "          2.6225e+00, -1.0338e+00,  7.6507e-01, -8.5038e-01,  2.5976e+00,\n",
      "         -4.4861e-01,  7.4363e-01, -8.8346e-01,  6.6358e-01, -1.4624e+00,\n",
      "          2.1042e+00, -7.4117e-01,  1.0430e-01,  5.0161e-01,  1.7648e+00,\n",
      "          4.9395e-01,  3.0738e+00,  2.9126e+00, -9.9545e-01,  2.8498e-02,\n",
      "          4.4942e-01, -8.7653e-01,  2.5575e+00,  1.7049e+00,  6.3541e-01,\n",
      "          4.0883e-02,  1.7377e+00, -3.9228e-01, -2.3795e-01,  1.7155e+00,\n",
      "          8.7199e-01,  2.4265e+00, -4.0927e-01,  3.1457e+00,  1.2322e+00,\n",
      "          2.0360e+00,  7.9884e-01, -6.3190e-01, -4.6468e-01, -5.8827e-01,\n",
      "          1.8529e+00, -7.8850e-01,  7.9699e-01,  6.6643e-01, -7.1299e-01,\n",
      "         -7.5411e-01, -7.6489e-01,  2.1469e+00,  4.4425e-01,  4.2223e-01,\n",
      "         -9.8011e-01,  7.4812e-01, -5.5103e-01, -8.0389e-01,  2.4605e+00,\n",
      "          6.6143e-01,  2.2808e+00,  6.0316e-02, -1.3984e+00, -5.4119e-01,\n",
      "          1.4097e+00,  1.1184e+00,  1.8639e+00,  2.2223e+00, -5.8433e-01,\n",
      "          1.2314e+00,  1.7117e+00, -1.4353e+00,  4.9039e-01, -1.5543e+00,\n",
      "         -5.1138e-01, -1.0938e+00, -5.6079e-01]], device='cuda:0')\n",
      "Layer: network.6.bias | Weights: tensor([-5.9409, -6.3465, -5.6428, -5.5773], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for name, param in value_action.qnetwork_other.named_parameters():\n",
    "    print(f\"Layer: {name} | Weights: {param.data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y, x = 1, 3\n",
    "wall_u = np.where(maze_map[:, x] == 1)[0]\n",
    "wall_u = y - wall_u[0] - 1\n",
    "wall_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keyboard in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (0.13.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_tile(tile):\n",
    "    if tile == 1:\n",
    "        return [1, 0, 0, 0]  # wall\n",
    "    elif tile == 0:\n",
    "        return [0, 1, 0, 0]  # empty\n",
    "    elif tile == 2:\n",
    "        return [0, 0, 1, 0]  # subgoal\n",
    "    elif tile == 3:\n",
    "        return [0, 0, 0, 1]  # goal\n",
    "\n",
    "one_hot_maze = np.array([[one_hot_encode_tile(tile) for tile in row] for row in maze_map])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_maze.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "maze_tensor = torch.tensor(one_hot_maze).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [1., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.],\n",
       "         [1., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maze_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
