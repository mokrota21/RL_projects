{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading torch-2.4.1-cp312-cp312-win_amd64.whl.metadata (27 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.4.1-cp312-cp312-win_amd64.whl (199.4 MB)\n",
      "   ---------------------------------------- 0.0/199.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/199.4 MB 12.5 MB/s eta 0:00:16\n",
      "    --------------------------------------- 3.7/199.4 MB 12.1 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.3/199.4 MB 9.9 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 9.4/199.4 MB 11.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 12.3/199.4 MB 11.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 14.9/199.4 MB 12.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 16.3/199.4 MB 11.1 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 18.4/199.4 MB 11.3 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 19.7/199.4 MB 10.6 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 22.3/199.4 MB 10.8 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 23.6/199.4 MB 10.3 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 26.5/199.4 MB 10.6 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 29.4/199.4 MB 10.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 32.5/199.4 MB 11.2 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 35.7/199.4 MB 11.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 37.7/199.4 MB 11.3 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 40.6/199.4 MB 11.5 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 43.8/199.4 MB 11.7 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 46.9/199.4 MB 11.8 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 50.1/199.4 MB 12.0 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 53.2/199.4 MB 12.1 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 56.4/199.4 MB 12.3 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 59.5/199.4 MB 12.4 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 62.4/199.4 MB 12.5 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 65.5/199.4 MB 12.6 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 68.7/199.4 MB 12.7 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 71.6/199.4 MB 12.7 MB/s eta 0:00:11\n",
      "   --------------- ------------------------ 75.0/199.4 MB 12.9 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 77.9/199.4 MB 12.9 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 81.0/199.4 MB 13.0 MB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 84.1/199.4 MB 13.1 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 87.0/199.4 MB 13.1 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 90.2/199.4 MB 13.2 MB/s eta 0:00:09\n",
      "   ------------------ --------------------- 93.1/199.4 MB 13.2 MB/s eta 0:00:09\n",
      "   ------------------- -------------------- 96.2/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 97.8/199.4 MB 13.3 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 99.1/199.4 MB 10.1 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 100.9/199.4 MB 10.1 MB/s eta 0:00:10\n",
      "   ------------------- ------------------- 102.0/199.4 MB 10.0 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 105.1/199.4 MB 10.1 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 108.3/199.4 MB 10.2 MB/s eta 0:00:09\n",
      "   --------------------- ----------------- 111.1/199.4 MB 10.2 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 114.6/199.4 MB 10.4 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 118.0/199.4 MB 10.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 119.3/199.4 MB 10.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 119.3/199.4 MB 10.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 119.3/199.4 MB 10.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 119.3/199.4 MB 10.5 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 119.5/199.4 MB 9.8 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 119.8/199.4 MB 9.7 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 120.8/199.4 MB 8.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 122.2/199.4 MB 7.8 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 125.3/199.4 MB 7.9 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 128.7/199.4 MB 8.0 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 131.9/199.4 MB 8.1 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 135.0/199.4 MB 8.2 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 137.4/199.4 MB 8.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 140.2/199.4 MB 8.3 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 143.4/199.4 MB 8.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 146.5/199.4 MB 8.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 149.4/199.4 MB 8.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 152.3/199.4 MB 8.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 155.2/199.4 MB 8.6 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 158.1/199.4 MB 8.7 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 161.2/199.4 MB 8.8 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 163.8/199.4 MB 8.8 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 165.7/199.4 MB 8.8 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 168.3/199.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 169.9/199.4 MB 8.8 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 172.8/199.4 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 175.9/199.4 MB 8.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 178.5/199.4 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 180.1/199.4 MB 9.0 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 182.7/199.4 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 185.6/199.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 188.0/199.4 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 190.6/199.4 MB 9.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 193.5/199.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  196.3/199.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  199.2/199.4 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 MB 9.1 MB/s eta 0:00:00\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 2.9/6.2 MB 14.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 11.2 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, setuptools, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.16.1 fsspec-2024.9.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 setuptools-75.1.0 sympy-1.13.3 torch-2.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "\n",
    "visibility = 2\n",
    "shape = (10, 10)\n",
    "map = np.random.rand(*shape) * 100\n",
    "vis_shape = map.shape\n",
    "vis_shape = (vis_shape[0] + visibility * 2, vis_shape[1] + visibility * 2)\n",
    "visibility_map = np.ones(shape=vis_shape, dtype=int) * -1\n",
    "visibility_map[visibility:-visibility, visibility:-visibility] = map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch)\n",
      "  Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.4.1-cp312-cp312-manylinux1_x86_64.whl (797.0 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached MarkupSafe-3.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
      "Successfully installed MarkupSafe-3.0.1 filelock-3.16.1 fsspec-2024.9.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 setuptools-75.1.0 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 10, 3], [491240, 10]]\n"
     ]
    }
   ],
   "source": [
    "l = [[1, 2, 3], [491240, 10]]\n",
    "s = l[0]\n",
    "s[1] = 10\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28.94, 71.09, 69.53, 12.11, 86.57, 61.12, 31.46, 31.98, 28.14,  2.46],\n",
       "       [ 1.96, 79.75, 99.95, 46.27, 35.79, 93.72, 50.66, 20.46, 10.4 , 38.85],\n",
       "       [78.75, 26.78, 26.94, 41.66, 63.43, 77.73, 58.65, 21.98, 78.72,  7.95],\n",
       "       [51.56, 90.23, 38.32, 93.94, 37.68, 70.25, 32.64,  3.38, 43.92,  7.15],\n",
       "       [ 6.66, 40.52, 96.55, 51.91,  1.77,  1.36, 29.04, 63.27, 37.56, 69.67],\n",
       "       [17.93,  3.19, 93.98,  4.56, 33.37, 76.47, 13.49, 36.  , 59.97, 50.24],\n",
       "       [77.43, 84.28, 44.8 , 94.62, 41.09, 58.32, 99.13, 38.96,  6.36, 33.97],\n",
       "       [61.53, 23.84, 72.  , 88.56, 88.37, 16.78, 69.27, 32.27, 45.66, 49.92],\n",
       "       [31.3 , 39.2 ,  5.19, 45.29, 41.52, 35.51, 12.23, 33.31, 18.77, 37.21],\n",
       "       [59.65, 65.33, 64.65, 34.15,  5.29, 24.18, 27.16, 65.55, 85.05, 84.49]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1, 28, 71, 69, 12, 86, 61, 31, 31, 28,  2, -1, -1],\n",
       "       [-1, -1,  1, 79, 99, 46, 35, 93, 50, 20, 10, 38, -1, -1],\n",
       "       [-1, -1, 78, 26, 26, 41, 63, 77, 58, 21, 78,  7, -1, -1],\n",
       "       [-1, -1, 51, 90, 38, 93, 37, 70, 32,  3, 43,  7, -1, -1],\n",
       "       [-1, -1,  6, 40, 96, 51,  1,  1, 29, 63, 37, 69, -1, -1],\n",
       "       [-1, -1, 17,  3, 93,  4, 33, 76, 13, 35, 59, 50, -1, -1],\n",
       "       [-1, -1, 77, 84, 44, 94, 41, 58, 99, 38,  6, 33, -1, -1],\n",
       "       [-1, -1, 61, 23, 71, 88, 88, 16, 69, 32, 45, 49, -1, -1],\n",
       "       [-1, -1, 31, 39,  5, 45, 41, 35, 12, 33, 18, 37, -1, -1],\n",
       "       [-1, -1, 59, 65, 64, 34,  5, 24, 27, 65, 85, 84, -1, -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visibility_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 28, 71, 69, -1, -1, 1, 79, 99, -1, -1, 78, 26, 26]\n",
      "[[-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 28 71 69]\n",
      " [-1 -1  1 79 99]\n",
      " [-1 -1 78 26 26]]\n"
     ]
    }
   ],
   "source": [
    "pos = 0, 0\n",
    "my_vision = visibility_map[pos[0]:2 * visibility + pos[0] + 1, pos[0]: 2 * visibility + pos[0] + 1]\n",
    "features = []\n",
    "for row in my_vision.tolist():\n",
    "    features += row\n",
    "print(features, my_vision, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = (0, 0)\n",
    "visibility = 2\n",
    "a[min(pos[0] - visibility) : pos[0] + visibility + 1, pos[1] - visibility : pos[1] + visibility + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.zeros((10, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reward Map tiles meaning\n",
    "EMPTY = 0\n",
    "SUBGOAL = -1\n",
    "GOAL = -2\n",
    "WALL = -3\n",
    "# AGENTS = n where n is number of agents on the tile\n",
    "\n",
    "maze_map = [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "            [1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
    "            [1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
    "            [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
    "            [1, 0, 1, SUBGOAL, 0, 0, 0, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
    "            [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
    "            [1, 0, 0, 0, 0, 0, 1, GOAL, 0, 1],\n",
    "            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3]\n",
    "print(l[:None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([9, 10, 1, 2])\n",
      "[9, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "d = deque([9, 10])\n",
    "d.append(1)\n",
    "d.append(2)\n",
    "print(d)\n",
    "d.pop()\n",
    "print(list(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 2, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.argmax(torch.tensor([[ 0.1, 0.4, 0.2, 0.8],\n",
    "        [ 0.9, 0.1, 0.3, 0.5],\n",
    "        [ 0.2, 0.5, 0.6, 0.4],\n",
    "        [ 0.7, 0.2, 0.8, 0.1],\n",
    "        [ 0.3, 0.9, 0.4, 0.1]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.tensor([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(int(torch.tensor([1, 2, 3])[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mokrota\\documents\\github\\rl_projects\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       " [1, 0, 1, 0, 1, 0, 1, 0, 1, 1],\n",
       " [1, 0, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
       " [1, 0, 1, -1, 0, 0, 0, 1, 0, 1],\n",
       " [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       " [1, 1, 1, 0, 1, 0, 1, 1, 0, 1],\n",
       " [1, 0, 0, 0, 0, 0, 1, -2, 0, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = np.array(maze_map)\n",
    "\n",
    "s.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "s = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "print(s[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []],\n",
       " [[], [], [], [], [], [], [], [], [], [], [], []]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[[] for _ in range(s.shape[1])] for _ in range(s.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a * 0\n",
    "a[(0, 0)] = 10.0\n",
    "# a[(0, 1)] = 10.0\n",
    "# a[(1, 0)] = 1.0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from greedy_fix import State, Action, Reward, Value, Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = Reward(a)\n",
    "value = Value(np.zeros((y, x)), dim=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create random equiprobable policy'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Create random equiprobable policy\"\"\"\n",
    "# p_m = np.ones((4, y, x))\n",
    "# p_m = p_m * 0.25\n",
    "# p_m[:, 0] = 1 / 3\n",
    "# p_m[:, -1] = 1 / 3\n",
    "# p_m[:, :, 0] = 1 / 3\n",
    "# p_m[:, :, -1] = 1 / 3\n",
    "# p_m[:, 0, 0] = 1 / 2\n",
    "# p_m[:, 0, -1] = 1 / 2\n",
    "# p_m[:, -1, 0] = 1 / 2\n",
    "# p_m[:, -1, -1] = 1 / 2\n",
    "# p_m[2, 0] = 0.0\n",
    "# p_m[0, -1] = 0.0\n",
    "# p_m[3, :, 0] = 0.0\n",
    "# p_m[1, :, -1] = 0.0\n",
    "# p_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create policy go down otherwise go up\"\"\"\n",
    "policy_m = np.zeros((4, y, x))\n",
    "policy_m[0] = 1.0\n",
    "policy_m[0, -1] = 0.0\n",
    "policy_m[2, -1] = 1.0\n",
    "print(policy_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = Policy(policy_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.1   0.  ]\n",
      " [ 1.01  0.  ]]\n",
      "Epoch: 0\n",
      "Value:\n",
      "[[10.1   0.  ]\n",
      " [ 1.01  0.  ]]\n",
      "Policy:\n",
      "     Down:\n",
      "[[1. 0.]\n",
      " [0. 0.]]\n",
      "     Right:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "     Up:\n",
      "[[0. 0.]\n",
      " [1. 0.]]\n",
      "     Left:\n",
      "[[0. 1.]\n",
      " [0. 1.]]\n",
      "Policy changes: 2\n",
      "------------------------------\n",
      "[[10.1   1.01]\n",
      " [ 1.01  0.1 ]]\n",
      "Epoch: 1\n",
      "Value:\n",
      "[[10.1   1.01]\n",
      " [ 1.01  0.1 ]]\n",
      "Policy:\n",
      "     Down:\n",
      "[[1. 0.]\n",
      " [0. 0.]]\n",
      "     Right:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "     Up:\n",
      "[[0. 0.]\n",
      " [1. 1.]]\n",
      "     Left:\n",
      "[[0. 1.]\n",
      " [0. 0.]]\n",
      "Policy changes: 1\n",
      "------------------------------\n",
      "[[10.1   1.01]\n",
      " [ 1.01  0.1 ]]\n",
      "Epoch: 2\n",
      "Value:\n",
      "[[10.1   1.01]\n",
      " [ 1.01  0.1 ]]\n",
      "Policy:\n",
      "     Down:\n",
      "[[1. 0.]\n",
      " [0. 0.]]\n",
      "     Right:\n",
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "     Up:\n",
      "[[0. 0.]\n",
      " [1. 1.]]\n",
      "     Left:\n",
      "[[0. 1.]\n",
      " [0. 0.]]\n",
      "Policy changes: 0\n",
      "------------------------------\n",
      "Final Value:\n",
      "[[10.1   1.01]\n",
      " [ 1.01  0.1 ]]\n",
      "Final Policy:\n",
      "[[[1. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[0. 1.]\n",
      "  [0. 0.]]]\n",
      "Maze:\n",
      "[[10.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "for i in range(epochs):\n",
    "    value.update(policy=policy, reward=reward)\n",
    "    # Print value\n",
    "    print(value.m)\n",
    "\n",
    "    changed = policy.update(value=value, reward=reward)\n",
    "    # Print Policy\n",
    "    print(f\"Epoch: {i}\")\n",
    "    print(f\"Value:\\n{value.m}\")\n",
    "    print(\"Policy:\")\n",
    "    print(f\"{' ' * 5}Down:\\n{policy.m[0]}\")\n",
    "    print(f\"{' ' * 5}Right:\\n{policy.m[1]}\")\n",
    "    print(f\"{' ' * 5}Up:\\n{policy.m[2]}\")\n",
    "    print(f\"{' ' * 5}Left:\\n{policy.m[3]}\")\n",
    "    print(f\"Policy changes: {changed}\")\n",
    "    print('-' * 30)\n",
    "\n",
    "    if changed == 0:\n",
    "        break\n",
    "\n",
    "print(f\"Final Value:\\n{value.m}\")\n",
    "print(f\"Final Policy:\\n{policy.m}\")\n",
    "print(f\"Maze:\\n{reward.m}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
